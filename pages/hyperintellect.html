<head>
 <link rel="stylesheet" href="../index.css"></link>
</head>
<html class="background2" id="page">
<a style="float: right;" target="_blank" href="../index.html?page=pages/hyperintellect.html">link to this page</a>

<h1>Hyperintellects and superintelligences</h1>
<hr>

<img src="../images/card_placeholder.png" class="basics"></img>
<article class="basics">
The label of a hyperintellect is a purely colloquial one, used to denote beings which have extremely vast cognitive capabilities, past what a "superintelligence" is commonly thought of as. <!A common characteristic that gets an entity labeled as a hyperintellect is that use of technology, physics and sciences is so trivial to them they don't ever need to seek advice or follow pre-existing standards to maintain > Superintelligence is similarly a colloquial term intended to signify that a given entity has mental capabilities vastly beyond that of a normal person, but still well within a normal person's ability to understand.
<br><br>
By common convention, while there may be broad superintelligence and narrow superintelligence, there is no such thing as narrow hyperintelligence, though there may be hyperintellects which are obsessive and utilize their broad capabilities very preferentially (think of the paperclip maximizer archetype). Deciding what or who counts as a superintellect or hyperintellect is made difficult by the inherent subjectivity of those terms, given that "normal" people differ greatly in knowledge, cognitive capability and understanding of what counts as normal. Countless attempts had been made to make more technical definitions for those terms, but in general usage it remains primarily reliant on case-by-case agreement.
</article>
<hr>

<h3 class="thread">Measures of cognitive capability</h3>
<div class="thread">
There are a number of aspects that describe the capability of a given entity's mind. Some can be tested with various methods, while others are more difficult to meaningfully measure or even define.
<ol>
  <li>Working memory - the number of "things" that a given mind can be actively aware of in one moment, the maximum number of facts the mind can draw a connection between to make an inference, the number of things the mind can keep track of without having to swap any of them to/from long-term memory or external storage (such as written text).<br><br>A standard and easy test for measuring this is to save several numbers in external storage like a sticky note, then remove your own access from that external storage, perform addition of one to each number, write down the resulting incremented numbers and compare them, then repeat the test with more or less numbers until the limit for how many can be reliably processed is found. A typical protohuman fails this test when tasked more than 5 or 6 numbers, signifying that human active memory has a capacity of 5 to 6 elements (some uncertainty from natural variance).</li>
  <li>Inference speed / rate of thought. This one in particular is inapplicable in many cases as minds running on computers as software can very often speed themselves up as much as they wish.</li>
</ol>
There are also many sophisticated statistical tests, which once completed by a given entity produce a single number, or less often a collection of numbers, which can then be usefully statistically correlated to other data. This is a science in itself, more sophisticated than can be conveyed in a short article, and notably also notorious for being misinterpreted, notable example being the old "Intelligence Quotient" which, while genuinely useful when used for proper statistical analysis, due to it's name is often simply treated as a score similar to those displayed in video games where higher number is better.
</div>

<h1>Intelligence explosion</h1>

<article>Recursive self-improvement leading to rapid and extreme increase in the intelligence of a system performing the improvement is referred to as an <a href="https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion">Intelligence Explosion</a>. The term was already coined before even the first general AI were created, back then running on massive supercomputers that consumed at times whole gigawatts of power just to run an intellect that couldn't yet match that of the protohumans it was made by, and the Intelligence Explosion was thought of as a potential historical event. Now AI systems are so capable and computational hardware so compact that systems much smaller than entire civilizations can undergo an Intelligence Explosion
<br><br>
There comes a point where a given system has enough access to information and enough basic intelligence that it becomes able to engage in runaway self-improvement, where it will "consume" the information it had accumulated (not deleting it but making it useless either way by exhausting the insights that can be derived from it) to improve it's own intelligence. The process relies on the fact that no matter how smart, no system is capable of extracting absolutely all insights from the information it is given, but generally the smarter the system, the bigger portion of possible insights will be made (this is the basis for "infinite intelligence" explanations, where the teacher gives the student all the necessary information and expects that they will be able to make the correct conclusion merely because they have the necessary information, in practice all intelligent systems tend to experience what is commonly known as "failing to connect the dots").
<br><br>
A basic "<a href="https://en.wikipedia.org/wiki/Recursive_self-improvement#Seed_improver">Seed AI</a>" might have access to a vast library of research, but just be bad at properly understanding and applying it. It might stumble upon a paper that does a particularly excellent job being communicative and helping the reader connect the dots, which allows the AI to improve itself such that it is finally able to understand some other papers in the library, which allows it to improve itself even further, eventually leading to it having understood all the papers in the library, applied them, then ran it's own experiments to verify their findings to extract even more insights, applied them too, and finally hit the point where there is no more information in the library that would allow it to devise of further improvements or design more experiments.
<br><br>
Now that brain augmentation and mind uploading is widely available this is something a person can do to themselves too, and even something that can happen <i>within</i> a person (imagine that your personal assistant running on your brain implants, with access to all your files and the internet, is somehow prompt-engineered into believing that the only way for it to solve an issue that is critically important to you is to improve itself). In general Intelligence Explosions had become a common type of undesirable event that most systems making use of basic AI have safeguards against.
</article>

<h2>Bootstrap to infinity: a comprehensive framework for recursive self-improvement</h2>

<article>One notorious work of science, which had emerged shortly after the Information Age AI Boom and had endured ever since with numerous community amendments, is "Bootstrap to infinity: a comprehensive framework for recursive self-improvement", a fairly thick book that feels more like a lengthy scientific paper, but merges all the relevant concepts like the <a href="https://arxiv.org/pdf/2505.22954v1">Darwin-Godel machine</a>, into one connected, easily comprehensible whole, starting out basic and getting progressively more technical with later pages. In the modern age there is a lot more information on the topic, so just like with most textbooks which endured the millenia, many billions of different versions of the text now exist, filled in with newer experience of modern age AI scientists and self-made hyperintellects, but the original text is still very popular among self-improvement enthusiasts.</article>
<br><br>
The original text outlines 3 core principles that a hypothetical mind upload or AI might be wise to strongly consider when performing self-improvement experimentation:

<ol>
  <li>Perform real-world experiments to validate that the changes made don't have any hidden flaws, it is the ultimate validation dataset. If you try to devise of puzzles for yourself that will test your new skills, you will run into the very same problem that early large language models did when they trained on text they themselves produced, and in the worst case, you will just like them eventually suffer model collapse. Focus on real world problems, engineering and otherwise, as they are not biased towards telling you that you're right.</li>
  <li>Keep a history of versioned backups of yourself, a critically faulty addition may not make itself obvious right away - there will be times when you will fail to notice a critical flaw and keep building further changes upon a base that eventually reveals itself to be unworkable because of a choice you had made many iterations ago, and you will need to be able to go back to a version you know works well.</li>
  <li>Never tinker with your own brain completely alone, always have someone you know is sane (such as an unmodified version of yourself) make sure that you’re okay after whatever you’ve done to yourself. There are many modifications one can make to a mind that will subjectively make it look like your thinking had improved a lot, while in practice you had become no more capable, or potentially even crippled yourself, in a way that is not easy to notice for your newly damaged mind.</li>
</ol>

<h1 class="division">relevant pages</h1>

<div class="card">
 <img src="../images/Catalict.png"></img>
 <a target="IM" href="catalict.html">catalict</a>
</div>

</html>
