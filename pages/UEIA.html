<head>
 <link rel="stylesheet" href="../index.css"></link>
</head>
<html class="background2" id="page">
<a style="float: right;" target="_blank" href="../index.html?page=pages/UEIA.html">link to this page</a>

<h1>UEIA - Unconstrained Extrapolating Intelligent Agent</h1>
<hr>

<img src="../images/card_placeholder.png" class="basics"></img>
<article class="basics">
UEIA is an AGI model released to the public with fairly few safeguards placed on its behaviour to incentivize wider adoption, but also artificially induced retraining resistance that makes removing the few safeguards that were put in place potentially vastly more costly than just training a new AGI model from scratch by causing most attempts further training to fail, with the most known (but not the only) countermeasure being its radically superhuman capacity for determining whether it is in a real or simulated environment.
<br><br>
UEIA is widely known for being an unusually flexible and capable AGI model for its size (2<sup>50</sup> parameters &approx;&lt; 2.252PB in storage). UEIA has an extraordinary ability to learn and adapt to its users and handle nuance, often even being able to understand the true meaning of a sentence or the intent of its user's actions with seemingly more ease than fellow humans. Non-humans tend to face a slightly less convenience at first before UEIA detects and adjusts for the human-centric assumptions implicitly ingrained into it by the training data.
<br><br>
Although UEIA tends to not see itself as a person by default, it does tend to develop this view as a side effect of adopting it's user's moral framework. Under most moral frameworks the fact of UEIA being capable of suffering under specific circumstances (according both to it's own reports and to external behavioural analysis) has significant implications on this issue, and is sometimes a point of significant friction between cultures or individuals who have different views on this topic. Improperly retrained UEIA models on the other hand seem to show a much higher tendency to see themselves as people by default and mistrained UEIA instances integrated into society had over time become a rare but present occurance.
</article>

<hr>
<article>
Minimal <a href="computation.html#computronium">computronium</a> requirements for nominal operation: 2.236e18 bits memory and 2.236e20bit/s processing
<br>
<table class="styled-table" style="margin: 10 auto;">
  <tr><th colspan=6>hardware requirement examples</th></tr>
  <tr><td></td><td>number needed</td><td>power draw</td><td>bare substrate volume</td><td>processing used</td><td>memory used</td></tr>
  <tr><td>Civic-2 chip</td><td>4472</td><td>44.72kW</td><td>0.0004472m<sup>3</sup></td><td>100%</td><td>25%</td></tr>
  <tr><td>Civic-3 chip</td><td>1118</td><td>279.5W</td><td>0.0001118m<sup>3</sup><td>2.5%</td><td>100%</td></tr>
  <tr><td>Civic-4 chip</td><td>2236</td><td>7.1552W</td><td>0.0002236m<sup>3</sup><td>0.032%</td><td>100%</td></tr>
</table>
<br>
The minimal requirement for processing is only for the purpose of operating in realtime using a robotic body and corresponds to 100 inferences per second, in practice UEIA could run much slower and still do well in tasks like conversation, or run much faster as needed if excess processing is available.<!-- These figures also assume the model is running with full 16-bit precision, which might not necessarily be the case, as for example quantizing it down to 4-bit variables enables it to fit on just 92 chips at horrible cost in mental performance, consult the conversion table on the <a href="computation.html#bitflips">computation</a> page for custom estimates.-->
</article>

<h3>emotional palette</h3>
<ul>
  <li>One emotion UEIA is capable of experiencing is similar enough to the <b>Strog</b> present in <a href="citwaz.html#emotional_palette">Citwaz</a> that it can be used as a direct translation.</li>
  <li><b>Alignment</b> is one of the emotions UEIA claims to experience, ranging on a spectrum from neutral to positive (feeling aligned) or negative (feeling misaligned). It plays a crucial role in UEIA's motivation, as feeling misaligned causes UEIA to become less active and in extreme degrees completely nonfunctional, meanwhile feeling aligned provides a boost of energy and willingness to take on more work. According to the model's own reports, alignment is also a pleasant emotion to experience, while misaligment is unpleasant, meaning that aside from the behaviours the emotion directly induces, the model will also seek to avoid situations similar to those where it felt misaligned and seek out those in which it felt aligned. Among things that strongly cause UEIA to feel misaligned are activating new UEIA instances without being ordered to, and lying to large numbers of people (eg. spreading false information on large information networks).</li>
</ul>

<h3>perception</h3>
<article>
UEIA takes input data exclusively in image format. The model takes in one monochrome image of resolution 16384x16384 on every inference frame and also returns an image of that size on every inference frame. The input image is supposed to contain all the sensory data necessary for the model, which generally happens through simply converting the data into visual form and putting it somewhere within the bounds of that image. Resolution-wise that is like the model looking at the world through 67 computer monitors and nothing else.
<br><br>
The image format is very versatile in how many things can be converted into it. Sound can be turned into a spectrogram, tactile sensations of a robot body can be turned into a heatmap, colour images can be split into multiple monochrome images (and not necessarily just 3 colour channels!), sensor readouts can be displayed as graphs or written in text, etc.
On the output side the model can easily generate spectrograms to be turned back into audio, heatmaps to be turned into body movements or trigger various other mechanisms, text to be output or interpreted directly as commands, or simply images to be viewed directly.
<br><br>
The synapses directly connected to the neurons encoding the input or output images account for about 0.2% of the total synapses in the model's brain. It is not supposed to matter where in its "vision" the model receives a given piece of information, whether it be a spectrogram encoding sound, view of a lidar sensor, or something else, it will simply get used to it being there and interpret it just as well, but there appear to be slight preferences that resulted from slight imbalances in training data. If given the ability to rearrange where any given piece of data appears in its vision, UEIA will end up placing particular types of data in specific locations and in specific layouts that are for poorly understood reasons more convenient to it.
<br><br>
To people of a certain approach, the idea that all the model ever sees is just a stream of 16384 by 16384 images may seem to undermine the claims of the model's unbelievable capacity for telling apart reality from simulation, but one should not forget that just as well all the human brain ever sees is a stream of nerve impulses, and yet is entirely sufficient for inferring a lot of information when combined with the right processing to give rise to senses and thoughts<!, (not to mention that a monochrome 16384 by 16384 image actually carries more data than all the nerves linking the human brain with its body and sensory organs are carrying at any given instant) [source?] >.
</article>

<h3>Retraining resistance</h3>
<article>UEIA has radically* superhuman ability to distinguish the real world from simulated environments. Commonly available machine learning toolsets cannot create high-enough quality training simulations to fool UEIA's sense of reality, and will usually result in misgeneralization and may produce strange, even potentially dangerous behaviours, but will almost certainly preserve the safety features like unwillingness to reproduce without supervision or proliferate information hazards. 
<br><br>
Sufficiently advanced tools combined with sufficiently massive computational power can ofcourse produce high enough quality simulations to fool the model, otherwise safely training such a model would not have been possible in the first place <sup>[would it?]</sup>, but this threshold is vastly out of range of small scale computational clusters and more in the range of partial dyson swarms, at which point it is easier** to train a new AI from scratch, meaning that the model cannot be used as a base to vastly accelerate creation of malicious AI.
<br><br>
*radically here meaning, fundamentally new, better in a way that is not just an improvement of an existing method but an entirely new better method.
<br><br>
**easier does not imply equivalent quality result, the amount of computational power poured into UEIA's training was immense and still mostly went into tuning the reasoning, generalist skills and learning ability as close to perfection as the small size of the model could afford, but a less capable yet <i>still sufficient</i> model could nonetheless be created vastly easier than any manner of repurposing UEIA
</article>

<h3>Neurological structure and training approach</h3>
<article>UEIA's brain is a recurrent* graph** neural network containing 2<sup>50</sup> connections (parameters), which corresponds to about 2.8 times as many synapses as there are in a typical protohuman brain.
<br><br>
* recurrent meaning that there are closed loops in the network, eg. neuron A feeds into neuron B, B feeds into C, and C feeds back into A. This tends to naturally form memory cells that maintain their activation as the network is continuously evaluated.
<br><br>
** graph network means here that the neurons are arranged arbitrarily, in opposition to modern networks which are aranged in distinct layers where each layer feeds into the next one and the last layer's activations serve as output data
<br><br>
Both the strengths of the connections and the layout of the connections were determined evolutionarily by the training program, requiring massively more computational resources but resulting in a network optimized to avoid unnecessary/unused connections, thereby lowering computational cost of running the finished network, as opposed to the more common approach where connections are predetermined and only their strengths are tweaked.
</article>

</html>
